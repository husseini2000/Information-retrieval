{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('where')\n",
    "stop_words.remove('to')\n",
    "stop_words.remove('is')\n",
    "\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loading and storing Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(filename, file):\n",
    "    filename = os.path.join('New folder',filename)\n",
    "    out = open(filename+'.pkl', 'wb')\n",
    "    pickle.dump(file, out)\n",
    "    out.close()\n",
    "    \n",
    "def load_pickle_data(file):\n",
    "    file = os.path.join('New folder',file)\n",
    "    out = open(file, 'rb')\n",
    "    index_dict1 = pickle.load(out)\n",
    "    out.close()\n",
    "    return index_dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_metadata(lines):\n",
    "    start = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i] == '\\n':\n",
    "            start = i + 1\n",
    "            break\n",
    "    return lines[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_words(words):\n",
    "    mod_words = []\n",
    "    global vocab\n",
    "    \n",
    "    # Remove punctuations.\n",
    "    table = str.maketrans('', '', '\\t')\n",
    "    words_list = [word.translate(table) for word in words]\n",
    "    trans_table = str.maketrans('', '', string.punctuation)\n",
    "    stripped_words = [word.translate(trans_table) for word in words_list]\n",
    "    words_list = [str for str in stripped_words if str]\n",
    "    \n",
    "    # Change to lowercase\n",
    "    # and Check if all the characters in the word is alphanumeric \n",
    "    for word in words_list:\n",
    "        word = word.lower()\n",
    "        if word.isalnum():\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            \n",
    "            if len(word) >= 2 and word not in stop_words:\n",
    "                vocab.add(word)\n",
    "                mod_words.append(word)\n",
    "    return mod_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(words):\n",
    "    tf_dict = {}\n",
    "    for key in words:\n",
    "        if key in tf_dict.keys():\n",
    "            tf_dict[key] += 1\n",
    "        else:\n",
    "            tf_dict[key] = 1\n",
    "    wtf_dict = tf_dict\n",
    "    for key in tf_dict.keys():\n",
    "        wtf_dict[key] = 1+ math.log10(wtf_dict[key])\n",
    "        \n",
    "    return tf_dict, wtf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(tf, positional_dict):\n",
    "    idf_dict = {}\n",
    "    N = 10\n",
    "    try:\n",
    "        for key in tf.keys():\n",
    "            if key in positional_dict.keys():\n",
    "                count = positional_dict[key][0]\n",
    "            else:\n",
    "                count = 0\n",
    "            idf = math.log10(N/(count))\n",
    "\n",
    "            idf_dict[key] = idf\n",
    "    except ZeroDivisionError:\n",
    "        idf_dict[key] = 0\n",
    "        \n",
    "    return idf_dict\n",
    "\n",
    "def idf_wrapper(docs_tf, positional_dict):\n",
    "    docs_idf = []\n",
    "    for tf in docs_tf:\n",
    "        idf = compute_idf(tf,positional_dict)\n",
    "        docs_idf.append(idf)\n",
    "    return docs_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(tf,idf):\n",
    "    tfidf = {}\n",
    "    for key in tf.keys():\n",
    "        val = tf[key] * idf[key]\n",
    "        tfidf[key] = val\n",
    "    return tfidf\n",
    "    \n",
    "\n",
    "def tfidf_wrapper(docs_tf,docs_idf):\n",
    "    docs_tfidf = []\n",
    "    for(tf,idf) in zip(docs_tf,docs_idf):\n",
    "        tfidf = compute_tfidf(tf,idf)\n",
    "        docs_tfidf.append(tfidf)\n",
    "    return docs_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(vocab,tfidf):\n",
    "    vector = {}\n",
    "    for key in vocab:\n",
    "        if key in tfidf.keys():\n",
    "            vector[key] = tfidf[key]\n",
    "        else:\n",
    "            vector[key] = 0.0\n",
    "    return vector\n",
    "\n",
    "def vectors_wrapper(vocab,docs_tfidf):\n",
    "    vectors = []\n",
    "    for tfidf in docs_tfidf:\n",
    "        vector = create_vector(vocab,tfidf)\n",
    "        vectors.append(vector)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Index Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(lines, positional_dict,doc_ID):\n",
    "    ''' This method is handle all the text in the file.\n",
    "    \n",
    "        This will remove meta data, pre process the file and construct the positional dictionary.\n",
    "        \n",
    "        positional dictionary format :\n",
    "            pos_dict = {\n",
    "                        token : [doc_freq,{\n",
    "                            file_id:[pos1, pos2,.....]\n",
    "                            }]\n",
    "                        }\n",
    "    '''\n",
    "    lines = remove_metadata(lines)\n",
    "    seperator = ' '\n",
    "    file = seperator.join(lines)\n",
    "    # Tokenize.\n",
    "    words = word_tokenize(file)\n",
    "    words = preprocessing_words(words)\n",
    "    doc_tf, doc_wtf = compute_tf(words)\n",
    "    for pos, word in enumerate(words):\n",
    "        if word in positional_dict.keys():\n",
    "            positional_dict[word][0] += 1 # doc frequency of word \n",
    "            if doc_ID in positional_dict[word][1].keys():\n",
    "                positional_dict[word][1][doc_ID].append(pos)\n",
    "            else:\n",
    "                positional_dict[word][1][doc_ID] = [pos] # adding the new file id and its position\n",
    "                \n",
    "        # If term does not exist in the positional index dictionary\n",
    "        # (first encounter).  \n",
    "        else :\n",
    "            positional_dict[word] = []\n",
    "            positional_dict[word].append(1)\n",
    "            positional_dict[word].append({})\n",
    "            positional_dict[word][1][doc_ID] = [pos]\n",
    "            \n",
    "    return doc_tf, doc_wtf, positional_dict     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in : New folder\n"
     ]
    }
   ],
   "source": [
    "file_mapper = {}\n",
    "docs_tf = []\n",
    "docs_wtf = []\n",
    "\n",
    "root_dirs = ['New folder']\n",
    "doc_ID = 0\n",
    "positional_dict = {}\n",
    "for fold in root_dirs:\n",
    "    print('Processing files in : {}'.format(fold))\n",
    "    \n",
    "    for file in os.listdir(fold):\n",
    "        path = os.path.join(fold,file)\n",
    "        \n",
    "        with open(path , 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            doc_tf, doc_wtf, positional_dict = process_text(lines,positional_dict,doc_ID)\n",
    "            docs_tf.append(doc_tf)\n",
    "            docs_wtf.append(doc_wtf)\n",
    "            file_mapper[doc_ID] = path\n",
    "            doc_ID += 1\n",
    "            if doc_ID % 100 == 0:\n",
    "                print('Processing of {} files in {} is completed '.format(doc_ID,fold))\n",
    "    docs_idf = idf_wrapper(docs_tf, positional_dict)\n",
    "    \n",
    "\n",
    "\n",
    "docs_tfidf = tfidf_wrapper(docs_tf,docs_idf)\n",
    "docs_vectors = vectors_wrapper(vocab,docs_tfidf)\n",
    "\n",
    "# pickling the dictionary\n",
    "pickle_data('positional_dict',positional_dict)\n",
    "pickle_data('pos_file_mapper',file_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of docs : 10\n",
      "Vocab Size :  14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "positional_dict = load_pickle_data('positional_dict.pkl')\n",
    "file_mapper = load_pickle_data('pos_file_mapper.pkl')\n",
    "\n",
    "N = len(docs_vectors)\n",
    "V = len(vocab)\n",
    "\n",
    "print('Num of docs :',N)\n",
    "print('Vocab Size : ',V)\n",
    "print(len(positional_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.DataFrame(docs_tf)\n",
    "df_wtf = pd.DataFrame(docs_wtf)\n",
    "df_idf = pd.DataFrame(docs_idf)\n",
    "df_vec = pd.DataFrame(docs_vectors)\n",
    "\n",
    "df_tf.to_csv('docs_tf.csv', index=False, encoding='utf-8-sig')\n",
    "df_wtf.to_csv('docs_wtf.csv', index=False, encoding='utf-8-sig')\n",
    "df_idf.to_csv('docs_idf.csv', index=False, encoding='utf-8-sig')\n",
    "df_vec.to_csv('docs_vectors.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9\n",
       "antony     1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "brutus     1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "caeser     1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
       "cleopatra  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "mercy      1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
       "worser     1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       "fool       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "fear       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0\n",
       "rush       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "to         0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "tread      0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "where      0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "calpurnia  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "angel      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf = pd.read_csv(\"docs_tf.csv\")\n",
    "df_tf = df_tf.T\n",
    "df_tf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4    5    6    7    8    9\n",
       "antony     1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "brutus     1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "caeser     1.0  0.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
       "cleopatra  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "mercy      1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0\n",
       "worser     1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       "fool       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "fear       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0\n",
       "rush       0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "to         0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "tread      0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "where      0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0\n",
       "calpurnia  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "angel      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wtf = pd.read_csv(\"docs_wtf.csv\")\n",
    "df_wtf = df_wtf.T\n",
    "df_wtf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2        3         4        5         6  \\\n",
       "antony     0.522879  0.000000  0.522879  0.00000  0.000000  0.00000  0.522879   \n",
       "brutus     0.522879  0.000000  0.522879  0.00000  0.522879  0.00000  0.000000   \n",
       "caeser     0.301030  0.000000  0.301030  0.00000  0.301030  0.30103  0.301030   \n",
       "cleopatra  1.000000  0.000000  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "mercy      0.301030  0.000000  0.000000  0.30103  0.301030  0.30103  0.301030   \n",
       "worser     0.397940  0.000000  0.000000  0.39794  0.397940  0.39794  0.000000   \n",
       "fool       0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "fear       0.000000  0.522879  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "rush       0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "to         0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "tread      0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "where      0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "calpurnia  0.000000  0.000000  1.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "angel      0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "\n",
       "                  7         8         9  \n",
       "antony     0.000000  0.000000  0.000000  \n",
       "brutus     0.000000  0.000000  0.000000  \n",
       "caeser     0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  \n",
       "mercy      0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  \n",
       "fool       0.397940  0.397940  0.397940  \n",
       "fear       0.522879  0.522879  0.000000  \n",
       "rush       0.397940  0.397940  0.397940  \n",
       "to         0.397940  0.397940  0.397940  \n",
       "tread      0.397940  0.397940  0.397940  \n",
       "where      0.397940  0.397940  0.397940  \n",
       "calpurnia  0.000000  0.000000  0.000000  \n",
       "angel      0.522879  0.522879  0.522879  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf = pd.read_csv(\"docs_idf.csv\")\n",
    "df_idf = df_idf.T\n",
    "df_idf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2        3         4        5         6  \\\n",
       "caeser     0.301030  0.000000  0.301030  0.00000  0.301030  0.30103  0.301030   \n",
       "to         0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "mercy      0.301030  0.000000  0.000000  0.30103  0.301030  0.30103  0.301030   \n",
       "worser     0.397940  0.000000  0.000000  0.39794  0.397940  0.39794  0.000000   \n",
       "antony     0.522879  0.000000  0.522879  0.00000  0.000000  0.00000  0.522879   \n",
       "fear       0.000000  0.522879  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "fool       0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "brutus     0.522879  0.000000  0.522879  0.00000  0.522879  0.00000  0.000000   \n",
       "cleopatra  1.000000  0.000000  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "tread      0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "angel      0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "where      0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "rush       0.000000  0.397940  0.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "calpurnia  0.000000  0.000000  1.000000  0.00000  0.000000  0.00000  0.000000   \n",
       "\n",
       "                  7         8         9  \n",
       "caeser     0.000000  0.000000  0.000000  \n",
       "to         0.397940  0.397940  0.397940  \n",
       "mercy      0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  \n",
       "antony     0.000000  0.000000  0.000000  \n",
       "fear       0.522879  0.522879  0.000000  \n",
       "fool       0.397940  0.397940  0.397940  \n",
       "brutus     0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  \n",
       "tread      0.397940  0.397940  0.397940  \n",
       "angel      0.522879  0.522879  0.522879  \n",
       "where      0.397940  0.397940  0.397940  \n",
       "rush       0.397940  0.397940  0.397940  \n",
       "calpurnia  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vec = pd.read_csv(\"docs_vectors.csv\")\n",
    "df_vec.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list(word):\n",
    "    '''\n",
    "    This will retrieve postings list of given token if exists\n",
    "    '''\n",
    "    ans = []\n",
    "    if word in positional_dict.keys():\n",
    "        #print('Term {} is present in the dictionary'.format(word))\n",
    "        ans =  positional_dict[word]\n",
    "    else:\n",
    "        print('Term : {} not present in dictionary'.format(word))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_intersect(pos_list_1,pos_list_2,k):\n",
    "    ans = []\n",
    "    for file_id in pos_list_1.keys():\n",
    "        if file_id in pos_list_2.keys():\n",
    "            list_1 = pos_list_1[file_id]\n",
    "            list_2 = pos_list_2[file_id]\n",
    "            \n",
    "            for pos1 in list_1:\n",
    "                for pos2 in list_2 :\n",
    "                    if pos2 - pos1 == k : #or pos1 - pos2 == k :\n",
    "                        if file_id not in ans:\n",
    "                            ans.append(file_id)\n",
    "                            #print('file found.')\n",
    "                        break\n",
    "    return ans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    results = []\n",
    "    query = preprocessing_words(query)\n",
    "    print('final query after preprocessing :')\n",
    "    print(query)\n",
    "    try:\n",
    "        for i in range(len(query)):\n",
    "            j = i + 1\n",
    "            pos_list_1 = retrieve_list(query[i])\n",
    "            while j < len(query):\n",
    "                pos_list_2 = retrieve_list(query[j])\n",
    "\n",
    "                swap = False\n",
    "                if pos_list_1[0] > pos_list_2[0]:\n",
    "                    #print('Swapping')\n",
    "                    pos_list_1, pos_list_2 = pos_list_2, pos_list_1\n",
    "                    swap = True\n",
    "                if swap :\n",
    "                    k = i - j\n",
    "                else :\n",
    "                    k = j - i\n",
    "                # Small postings list is always first one for optimisation\n",
    "                ans = positional_intersect(pos_list_1[1], pos_list_2[1], k)\n",
    "                results.append(ans)\n",
    "                j += 1\n",
    "    except:\n",
    "        retrieve_list(query[i])\n",
    "    return query, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(query_vec, matched_vec):\n",
    "    \n",
    "    vec_a = []\n",
    "    vec_b = []\n",
    "    for key in query_vec.keys():\n",
    "        vec_a.append(query_vec[key])\n",
    "        vec_b.append(matched_vec[key])\n",
    "    \n",
    "    mod_a = np.sqrt(sum(np.square(vec_a)))\n",
    "    mod_b = np.sqrt(sum(np.square(vec_b)))\n",
    "    if mod_a == 0.0 or mod_b == 0.0 :\n",
    "        score = 0\n",
    "    else:\n",
    "        score = np.dot(vec_a,vec_b)/(mod_a * mod_b)\n",
    "    #print('score ',score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def cosine_wrapper(vector, matched_vectors):\n",
    "    dummy = []\n",
    "    for vec in matched_vectors:\n",
    "        dummy.append(cosine(vector, vec))\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_query_score(query, positional_dict, matched_vectors):\n",
    "    \n",
    "    tf, _ = compute_tf(query)\n",
    "    idf = compute_idf(tf,positional_dict)\n",
    "    tfidf = compute_tfidf(tf,idf)\n",
    "\n",
    "    vector = create_vector(vocab, tfidf)\n",
    "    score = cosine_wrapper(vector,matched_vectors)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query, positional_dict, matched_vectors):\n",
    "    score = find_query_score(query, positional_dict, matched_vectors)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dict(lists):\n",
    "    results = {}\n",
    "    for lis in lists:\n",
    "        for ele in lis:\n",
    "            if ele in results.keys():\n",
    "                results[ele] += 1\n",
    "            else:\n",
    "                results[ele] = 1\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(results, score):\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The most probable files for given phrasal query in descending order is : ')\n",
    "    i = 0\n",
    "    path = []\n",
    "    for key in results.keys():\n",
    "        path.append(file_mapper[key])\n",
    "        \n",
    "    files_score = list(zip(score, path))\n",
    "    files_score = sorted(files_score, reverse=True)\n",
    "    \n",
    "    for index, value in enumerate(files_score):\n",
    "        print('file {} is {} with score: {}'.format(i+1,value[1], value[0]))\n",
    "        i += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched_docs(results, docs_vectors):\n",
    "    matched_vector = []\n",
    "    matched_vectors = []\n",
    "    for key in results.keys():\n",
    "        matched_vector = docs_vectors[key]\n",
    "        matched_vectors.append(matched_vector)\n",
    "    return matched_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_query():\n",
    "    query = input().split()\n",
    "    query, results = process_query(query)\n",
    "    results = construct_dict(results)\n",
    "    matched_vectors = matched_docs(results, docs_vectors)\n",
    "    score = calculate_similarity(query, positional_dict, matched_vectors)\n",
    "    print_output(results, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brutus ahmed\n",
      "final query after preprocessing :\n",
      "['brutus', 'ahmed']\n",
      "Term : ahmed not present in dictionary\n",
      "-----------------------\n",
      "The most probable files for given phrasal query in descending order is : \n"
     ]
    }
   ],
   "source": [
    "read_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
